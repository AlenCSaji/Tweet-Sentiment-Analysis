{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "769d81b9-f67f-47f5-825d-e6f918e82347",
   "metadata": {
    "id": "769d81b9-f67f-47f5-825d-e6f918e82347"
   },
   "source": [
    "# **Single Layer Unidirectional LSTM Model using word2vec**\n",
    "### - (CBOW or Skipgram and any vector size from 64 to 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dc77df-af4a-43e0-9370-e457a6d019ce",
   "metadata": {
    "id": "32dc77df-af4a-43e0-9370-e457a6d019ce"
   },
   "source": [
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jutL3-DiUdri",
   "metadata": {
    "id": "jutL3-DiUdri"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc, f1_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense, Bidirectional\n",
    "from sklearn.utils import class_weight\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a490e3f1-f284-4c0d-ae64-b5ef9d30daa1",
   "metadata": {
    "id": "a490e3f1-f284-4c0d-ae64-b5ef9d30daa1"
   },
   "source": [
    "## **Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aaed64a-b5b6-42b7-976a-fd8eeb580e91",
   "metadata": {
    "id": "4aaed64a-b5b6-42b7-976a-fd8eeb580e91"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train = pd.read_csv(\"X_train.csv\")[\"Final_Cleaned_Tweet\"]\n",
    "X_val = pd.read_csv(\"X_val.csv\")[\"Final_Cleaned_Tweet\"]\n",
    "X_test = pd.read_csv(\"X_test.csv\")[\"Final_Cleaned_Tweet\"]\n",
    "\n",
    "y_train = pd.read_csv(\"y_train.csv\")[\"Sentiment\"]\n",
    "y_val = pd.read_csv(\"y_val.csv\")[\"Sentiment\"]\n",
    "y_test = pd.read_csv(\"y_test.csv\")[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46831729-1019-4e52-bd30-171e9ee12137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    truth evil becomes apparent every day american...\n",
       "1    cap youngster initial arrest tan pant right ta...\n",
       "2    freedom convoy organizer tamara rich return ot...\n",
       "3                tamara lich arrest fafo freedomconvoy\n",
       "4    pal ukraine fight real freedom convoy forming ...\n",
       "Name: Final_Cleaned_Tweet, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2wFrqgTQZ6eE",
   "metadata": {
    "id": "2wFrqgTQZ6eE"
   },
   "source": [
    "## **Label Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5D7avm_XZYSB",
   "metadata": {
    "id": "5D7avm_XZYSB"
   },
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8bdc51f2-763b-41fd-8d6a-b094a0ac71f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 3, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KC1yskj-ZvRK",
   "metadata": {
    "id": "KC1yskj-ZvRK"
   },
   "source": [
    "## **Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "VfZLd3fZWX0X",
   "metadata": {
    "id": "VfZLd3fZWX0X"
   },
   "outputs": [],
   "source": [
    "# Convert all entries to string and handle NaNs\n",
    "X_train = X_train.fillna(\"\").astype(str)\n",
    "X_val = X_val.fillna(\"\").astype(str)\n",
    "X_test = X_test.fillna(\"\").astype(str)\n",
    "\n",
    "# Now combine all for tokenizer\n",
    "all_text = pd.concat([X_train, X_val, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "NaC_KXNaVrV9",
   "metadata": {
    "id": "NaC_KXNaVrV9"
   },
   "outputs": [],
   "source": [
    "# Fit tokenizer on all text data\n",
    "all_text = pd.concat([X_train, X_val, X_test])\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_text)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text to sequences\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Padding\n",
    "max_len = max(len(seq) for seq in X_train_seq)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len, padding='post')\n",
    "X_val_pad = pad_sequences(X_val_seq, maxlen=max_len, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2gYQnUZNduuU",
   "metadata": {
    "id": "2gYQnUZNduuU"
   },
   "source": [
    "## **Embedding - Word2Vec (Skip-gram)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "081a0d53-dcb5-48c8-9bea-594dbc3c993a",
   "metadata": {
    "id": "081a0d53-dcb5-48c8-9bea-594dbc3c993a"
   },
   "outputs": [],
   "source": [
    "# Train Word2Vec (Skip-gram)\n",
    "tokenized_sentences = [sentence.split() for sentence in all_text]\n",
    "embedding_dim = 100\n",
    "w2v_model = Word2Vec(sentences=tokenized_sentences, vector_size=embedding_dim, window=5, min_count=1, sg=1)\n",
    "\n",
    "# Create embedding matrix\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in w2v_model.wv:\n",
    "        embedding_matrix[i] = w2v_model.wv[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "POLPVaBDWv74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "POLPVaBDWv74",
    "outputId": "868e1879-6128-416b-b14c-3fd59cb77396"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,105,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │       \u001b[38;5;34m3,105,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m117,248\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,223,093</span> (12.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,223,093\u001b[0m (12.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,893</span> (460.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m117,893\u001b[0m (460.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,105,200</span> (11.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,105,200\u001b[0m (11.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=False))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Build model explicitly\n",
    "model.build(input_shape=(None,max_len))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5e08bf7-d56a-4552-99a5-221ce788891e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5e08bf7-d56a-4552-99a5-221ce788891e",
    "outputId": "c709c011-8a17-447d-b9b0-2541f6e4bb81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 41ms/step - accuracy: 0.2631 - loss: 1.5721 - val_accuracy: 0.3460 - val_loss: 1.4713\n",
      "Epoch 2/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.3337 - loss: 1.4895 - val_accuracy: 0.4500 - val_loss: 1.3128\n",
      "Epoch 3/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 38ms/step - accuracy: 0.3751 - loss: 1.4272 - val_accuracy: 0.4252 - val_loss: 1.3685\n",
      "Epoch 4/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.3999 - loss: 1.3941 - val_accuracy: 0.4397 - val_loss: 1.3112\n",
      "Epoch 5/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.4011 - loss: 1.3860 - val_accuracy: 0.5225 - val_loss: 1.2053\n",
      "Epoch 6/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 40ms/step - accuracy: 0.4200 - loss: 1.3632 - val_accuracy: 0.5447 - val_loss: 1.1864\n",
      "Epoch 7/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 39ms/step - accuracy: 0.4223 - loss: 1.3439 - val_accuracy: 0.5070 - val_loss: 1.2422\n",
      "Epoch 8/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.4349 - loss: 1.3283 - val_accuracy: 0.5490 - val_loss: 1.1532\n",
      "Epoch 9/10\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.4419 - loss: 1.3129 - val_accuracy: 0.5770 - val_loss: 1.1680\n",
      "Epoch 10/10\n",
      "\u001b[1m237/421\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - accuracy: 0.4426 - loss: 1.3106"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m early_stop = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m2\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_enc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_enc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad, y_train_enc,\n",
    "                    validation_data=(X_val_pad, y_val_enc),\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-qM8CwAogCd-",
   "metadata": {
    "id": "-qM8CwAogCd-"
   },
   "source": [
    "## **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadbd1b8-4c6b-4336-bdb5-47061d2e571a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cadbd1b8-4c6b-4336-bdb5-47061d2e571a",
    "outputId": "4afd5ce3-1227-41c9-d0e0-b33772f8f3df"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_train_pad, y_train_enc)\n",
    "print(f\"Train Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dea054-9fb9-4d47-b281-5970e0a63ddd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51dea054-9fb9-4d47-b281-5970e0a63ddd",
    "outputId": "994c2834-5c89-4b6e-9c8b-48b98a2109ad"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, y_test_enc)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13f7eda-1371-4de0-857f-d289be1006fd",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The model is clearly underfitting on the training data (39%) while performing much better on the test set (57%), which is unusual. This likely points to over-regularization, overly aggressive class weighting, or a learning dynamic where the model is better tuned to the test distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffac1c2f-544d-4f81-ba23-57800aca8b2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "id": "ffac1c2f-544d-4f81-ba23-57800aca8b2b",
    "outputId": "2467bf74-2d17-4c2f-8eec-534576b59b54"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Me9FjSSqi-xw",
   "metadata": {
    "id": "Me9FjSSqi-xw"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9caa71-b0a3-4919-9b0d-b3cc276e8868",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GLe_-tMFhDWZ",
   "metadata": {
    "id": "GLe_-tMFhDWZ"
   },
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_train_pred = np.argmax(model.predict(X_train_pad), axis=1)\n",
    "y_train_proba = model.predict(X_train_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_train_enc, y_train_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Train Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_train_enc, y_train_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_train_enc, y_train_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f863044b-ff30-4a0c-a918-a7b73551871d",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "This confusion matrix confirms that the model is underfitting on the training set, with only one class (Strong_Pos) being robustly predicted. All other classes, especially Mild_Neg, Mild_Pos, and Neutral, suffer from significant confusion — particularly being misclassified as Strong_Pos. This could stem from imbalanced class distribution, inadequate learning, or over-regularization. The model also shows signs of sentiment polarity confusion, indicating deeper issues in its understanding of tone and intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301a150b-f1c6-4678-9f38-1a122859aec9",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f175503-89ac-47b2-8f3b-c7237fad3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_test_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "y_test_proba = model.predict(X_test_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_enc, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_test_enc, y_test_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_test_enc, y_test_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31dfea8-34f2-43b5-ab3e-2995b5d42fc7",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The model performs very confidently on strongly positive tweets, but struggles with subtle sentiment expressions. It frequently misclassifies mild or neutral classes as stronger sentiments, suggesting it has learned dominant emotional cues but lacks nuance. This is a common challenge in real-world sentiment classification, especially without deeper contextual models or more balanced class handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sFCEZZ4Oi62j",
   "metadata": {
    "id": "sFCEZZ4Oi62j"
   },
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cbb675-6122-40b3-83e6-0b366abf608b",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eU51xNCvi6g2",
   "metadata": {
    "id": "eU51xNCvi6g2"
   },
   "outputs": [],
   "source": [
    "# Macro, Micro, Weighted\n",
    "f1_macro = f1_score(y_train_enc, y_train_pred, average='macro')\n",
    "f1_micro = f1_score(y_train_enc, y_train_pred, average='micro')\n",
    "f1_weighted = f1_score(y_train_enc, y_train_pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1 Score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2386b-72fd-485a-99ec-40a4977be0ac",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5c309-570b-4695-87ac-16cd541e9e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro, Micro, Weighted\n",
    "f1_macro = f1_score(y_test_enc, y_test_pred, average='macro')\n",
    "f1_micro = f1_score(y_test_enc, y_test_pred, average='micro')\n",
    "f1_weighted = f1_score(y_test_enc, y_test_pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1 Score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pS8bAsZpi72P",
   "metadata": {
    "id": "pS8bAsZpi72P"
   },
   "source": [
    "#### ROC AUC Plot (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a222e566-8364-484f-be64-83bda615ba1a",
   "metadata": {},
   "source": [
    "#### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6140df-35b7-4621-8cf3-b5552aeeb0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_train_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_train_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Train Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4ef86c-a530-4f7e-a09f-32b9b9c9bdac",
   "metadata": {},
   "source": [
    "#### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Bbj1rk29i81S",
   "metadata": {
    "id": "Bbj1rk29i81S"
   },
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_test_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_test_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Test Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "j3HL7SbNbfl5",
   "metadata": {
    "id": "j3HL7SbNbfl5"
   },
   "source": [
    "# **Model Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da597507-723d-4ad5-9001-e953ef6dfeb9",
   "metadata": {},
   "source": [
    "### **Iteration #1- Allow Embedding Layer to Fine-Tune (Trainable=True)**\n",
    "\n",
    "This approach will help backpropagation to update the Word2Vec vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2467067f-30d9-4574-b636-6f6c7482aba3",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VJk4m-IBbbTU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "VJk4m-IBbbTU",
    "outputId": "d97daa11-f5c3-4121-9cdf-9486c2ccd3d8"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    trainable=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Build model explicitly\n",
    "model.build(input_shape=(None,max_len))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "W3gvFxtecDbg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W3gvFxtecDbg",
    "outputId": "a0cf2a91-ee74-4687-b124-f39c798309ac"
   },
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad, y_train_enc,\n",
    "                    validation_data=(X_val_pad, y_val_enc),\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XEbxvVRhhO5U",
   "metadata": {
    "id": "XEbxvVRhhO5U"
   },
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2SUvwkhLfIVf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2SUvwkhLfIVf",
    "outputId": "96c8aea0-a7d0-412e-ee83-7fa1628743b4"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_train_pad, y_train_enc)\n",
    "print(f\"Train Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X5rPfu_8fWIi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X5rPfu_8fWIi",
    "outputId": "6567d260-8b62-49ca-b201-f1219ad21a06"
   },
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, y_test_enc)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9919c4-ed60-4577-945f-44c16fd07e29",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "The model achieves balanced train and test accuracy at 56%, showing no overfitting and good generalization. The lower test loss further confirms that predictions on test samples are relatively well-calibrated. While the model performs stably, there is still room for improvement in handling ambiguous or subtle sentiment classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4RxBvOKmhXGX",
   "metadata": {
    "id": "4RxBvOKmhXGX"
   },
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_VLH9U2yfiKk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "_VLH9U2yfiKk",
    "outputId": "a4469627-e286-4dbd-d9a0-0f926d30563d"
   },
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_train_pred = np.argmax(model.predict(X_train_pad), axis=1)\n",
    "y_train_proba = model.predict(X_train_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_train_enc, y_train_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Train Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_train_enc, y_train_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_train_enc, y_train_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef4fd68-2d2e-46d2-ab55-79f17b0e04aa",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The model performs best on extreme sentiment classes like Strong_Pos and Strong_Neg, indicating that high-intensity emotional cues are learned well. However, it struggles with mild and neutral sentiments, frequently confusing them with each other or with their stronger counterparts. The difficulty in predicting Neutral and Mild_Neg suggests that the model finds it hard to distinguish between weak tone and neutrality, which is common in real-world sentiment analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3d62f-8661-4238-b20f-1f46d1c0fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_test_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "y_test_proba = model.predict(X_test_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_enc, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_test_enc, y_test_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_test_enc, y_test_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835cd7d-44a5-4fa1-b2c7-ac01782fb217",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "The model performs best on strong sentiment classes (Strong_Pos, Strong_Neg) — those with clearer linguistic signals. However, it has difficulty distinguishing mild and neutral sentiments, often mistaking neutral for weak sentiment and confusing mild with strong intensity. Polarity confusion (e.g., Mild_Pos ↔ Mild_Neg) is also noticeable, suggesting that the model captures sentiment intensity better than sentiment direction for subtle cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ggucdk_Mhdis",
   "metadata": {
    "id": "ggucdk_Mhdis"
   },
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HSlKrN6qhk6z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSlKrN6qhk6z",
    "outputId": "76dfa342-dacc-4a86-d0a0-97494a4877b1"
   },
   "outputs": [],
   "source": [
    "# Macro, Micro, Weighted\n",
    "f1_macro = f1_score(y_train_enc, y_train_pred, average='macro')\n",
    "f1_micro = f1_score(y_train_enc, y_train_pred, average='micro')\n",
    "f1_weighted = f1_score(y_train_enc, y_train_pred, average='weighted')\n",
    "print(\"Train Set\")\n",
    "print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1 Score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b75ace-1d7c-4fc3-a044-aa3a693dfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro, Micro, Weighted\n",
    "f1_macro = f1_score(y_test_enc, y_test_pred, average='macro')\n",
    "f1_micro = f1_score(y_test_enc, y_test_pred, average='micro')\n",
    "f1_weighted = f1_score(y_test_enc, y_test_pred, average='weighted')\n",
    "print(\"Test Set\")\n",
    "print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1 Score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kr_b_czKiMhF",
   "metadata": {
    "id": "kr_b_czKiMhF"
   },
   "source": [
    "#### ROC AUC Plot (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GzmbQWPuiPwH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "GzmbQWPuiPwH",
    "outputId": "41a9dfd9-1fcf-4e01-cc77-e14b663771c6"
   },
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_test_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_train_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Train Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8e3175-0d3f-4c7a-9b6f-993c131c8952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_test_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_test_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Test Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ff2b39-1f38-4f0f-ab01-f61c0185c4d1",
   "metadata": {},
   "source": [
    "## **Iteration #2 - Add More Capacity (Dense Layer Before Output)**\n",
    "\n",
    "By adding a Dense layer with 128 ReLU units, we introduce a nonlinear transformation before making the final classification decision.\n",
    "This lets the model learn more abstract representations and interactions between features captured by the LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5a480-e626-4f5a-a4cb-dcc0ca9ff0fe",
   "metadata": {},
   "source": [
    "### Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32301af-20ae-4d60-92d1-1f624ac3cdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))  # NEW hidden layer\n",
    "model.add(Dropout(0.3))  # Optional second dropout\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_len))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c91a5c1-0a94-4bcb-8090-52d46983002e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad, y_train_enc,\n",
    "                    validation_data=(X_val_pad, y_val_enc),\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f685a1-9555-462a-a726-20ad1d1f8eea",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121ef12b-addc-440c-af4a-bc1a895eaccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_train_pad, y_train_enc)\n",
    "print(f\"Train Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3249934-2bc7-431e-8d82-726b5ca57a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, y_test_enc)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645050dd-4be6-4ab4-985b-9f34eb474cbb",
   "metadata": {},
   "source": [
    "### Observations and Summary\n",
    "\n",
    "From the above Test and Train accuracy we observe a close test and train accuracy. The model achieves a training accuracy of 56% and a test accuracy of 55%, indicating that it is generalizing well with no signs of overfitting. \n",
    "\n",
    "Since both accuracies are closely aligned, the model is not memorizing the training data and is performing consistently across unseen data. \n",
    "\n",
    "However, the moderate accuracy suggests mild underfitting, meaning the model could still improve its ability to capture more complex patterns in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c1c518-542c-48a7-8436-ff8a7c7cf5c3",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564fda7e-1bf1-4136-9ae2-4804479ca319",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c55a391-262a-4d59-9783-f67b8b391dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_train_pred = np.argmax(model.predict(X_train_pad), axis=1)\n",
    "y_train_proba = model.predict(X_train_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_train_enc, y_train_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Train Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_train_enc, y_train_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_train_enc, y_train_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0654e-d95e-43f8-a958-e89f012338af",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "The model performs very well on extreme classes (Strong_Pos, Strong_Neg)\n",
    "\n",
    "It struggles more with subtle distinctions between Mild_Neg, Neutral, and Mild_Pos\n",
    "\n",
    "This is typical for sentiment models — mild and neutral sentiments often overlap semantically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838f3fbe-40f7-4d46-8e7f-b2473953c709",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7170d3-df77-42d6-9401-eaa20532a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_test_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "y_test_proba = model.predict(X_test_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_enc, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_test_enc, y_test_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_test_enc, y_test_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb24f31-d5de-48c3-94c0-794fecd25d18",
   "metadata": {},
   "source": [
    "#### Summary \n",
    "\n",
    "Strong_Pos is the best learned class — model captures highly positive tweets effectively.\n",
    "\n",
    "Neutral, Mild_Neg, and Mild_Pos are frequently confused, which is common in sentiment classification due to overlapping language tones.\n",
    "\n",
    "Strong_Neg classification is weaker, likely due to lower representation or subtle expression variance.\n",
    "\n",
    "The model has learned to identify strong sentiment better than mild or neutral, which typically requires more nuanced feature understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21013ba-b989-4846-8155-c58c73deda4d",
   "metadata": {},
   "source": [
    "#### ROC AUC Plot (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfb5e5-448f-4105-8703-b36d563ec0ce",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9772b15-ba80-41dd-a9fb-671d6b1f6d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_train_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_train_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Train Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d17a51-4a98-4f23-9e23-f91716c066e9",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a975fa-149d-43c2-90af-de4b58bb8a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_test_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_test_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Test Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e687d-5692-4c65-8655-906ad4f89564",
   "metadata": {},
   "source": [
    "## **Iteration #3- Adding another LSTM Layer (Stacked LSTM)**\n",
    "\n",
    "Here we are adding an additional LSTM layer LSTM(64) which takes the sequence output from the first LSTM and summarizes it. It outputs a single 64-dimensional vector representing the whole input sequence again, but now with deeper context.\n",
    "This captures higher-level sequential patterns in the tweet text.\n",
    "\n",
    "First LSTM learns local patterns → second LSTM learns long-term global relationships.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dba98-d34f-4bf7-9f46-cd74b3aff4a3",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb527ca-d3e1-47e3-a772-ca6d6121fdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=True))\n",
    "model.add(LSTM(128, return_sequences=True))  # keep output sequences\n",
    "model.add(LSTM(64))                          # new second LSTM\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build(input_shape=(None, max_len))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29574e6-b9e4-4fff-bf3a-8a8b996d9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad, y_train_enc,\n",
    "                    validation_data=(X_val_pad, y_val_enc),\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e4edb-6863-4c1b-8489-f068d0d2fcf4",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a57b71-93b8-4de3-becd-7a38070dbf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_train_pad, y_train_enc)\n",
    "print(f\"Train Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfec82-b165-44da-bf2c-1b2eb4243836",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, y_test_enc)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23925446-568d-406d-96cf-4248e2c41753",
   "metadata": {},
   "source": [
    "#### Observations and Summary\n",
    "\n",
    "Stacking LSTM layers has slightly improved test performance compared to the the earlier single-layer models.\n",
    "\n",
    "That implies the second LSTM is helping the model understand deeper sequential dependencies.\n",
    "\n",
    "But the jump is still small, hinting that further architectural or data improvements may be needed for substantial gains.\n",
    "\n",
    "The model achieved a training accuracy of 56% and a test accuracy of 57%, indicating that it is generalizing well with no signs of overfitting. Since both accuracies are nearly identical, the model is not memorizing the training data but is performing consistently on unseen data. However, the overall accuracy still suggests mild underfitting, meaning the model has not yet captured all the complex patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441cd545-095e-4351-976d-d8db18104f60",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de09dc87-9d91-4c49-9007-972f2145de93",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf92887b-50a2-488b-862a-cf9cb53a97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_train_pred = np.argmax(model.predict(X_train_pad), axis=1)\n",
    "y_train_proba = model.predict(X_train_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_train_enc, y_train_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Train Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_train_enc, y_train_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_train_enc, y_train_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1011ce1-a83f-40ee-b5ef-1ec5fb003ee1",
   "metadata": {},
   "source": [
    "#### Observations \n",
    "\n",
    "Performs well on extreme sentiments (especially Strong_Pos and Strong_Neg)\n",
    "\n",
    "Struggles with mild and neutral sentiments, which is typical in fine-grained sentiment analysis\n",
    "\n",
    "Suggests that contextual nuances (like sarcasm or negation) are still challenging for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899cc43e-43c0-4ca6-993d-910711a1ed19",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c82a373-85d2-41f2-b6b2-bece4f3ec903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_test_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "y_test_proba = model.predict(X_test_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_enc, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_test_enc, y_test_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_test_enc, y_test_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4dbaae-52cd-4555-8d5d-315ebd50b6a2",
   "metadata": {},
   "source": [
    "#### Summary \n",
    "\n",
    "The stacked LSTM model generalizes well on the test set and performs strongly on clearly polarized sentiments (Strong_Pos, Strong_Neg).\n",
    "However, the model struggles with subtle sentiments (Neutral, Mild_Pos, Mild_Neg) where distinctions rely on context, tone, or nuanced wording. This confusion leads to moderate misclassifications across mid-spectrum classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528f251e-edfe-4e5b-9a1c-e426083d0531",
   "metadata": {},
   "source": [
    "#### ROC AUC Plot (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130bf651-9eba-4bdc-8f69-5f83dd62c36c",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fed2bd-68bf-4be2-89f0-f22e12f26a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bin = label_binarize(y_train_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_train_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Train Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe43de-32c5-4d7b-856e-a818f1d600a7",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c016ef1c-102c-4650-9b05-4e2ff40be0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_test_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_test_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Test Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ad767-3ff3-48ca-a0fc-5d969ce3a404",
   "metadata": {},
   "source": [
    "## **Iteration #4- Bidirectional LSTM**\n",
    "\n",
    "A Bidirectional LSTM processes a sequence in both forward and backward directions, allowing the model to access past and future context at every time step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1fcea2-4209-4932-b1af-398539fe1212",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0241643-44d6-4ca8-a3f3-84a6754185b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,105,200</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">234,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m51\u001b[0m, \u001b[38;5;34m100\u001b[0m)             │       \u001b[38;5;34m3,105,200\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m234,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │             \u001b[38;5;34m645\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,373,237</span> (12.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,373,237\u001b[0m (12.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,373,237</span> (12.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,373,237\u001b[0m (12.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Word2Vec Embedding Layer (trainable for fine-tuning)\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=True))\n",
    "\n",
    "# Bidirectional LSTM\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=False)))  # You can try return_sequences=True for stacking\n",
    "\n",
    "# Dropout for regularization\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Fully connected layer\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer for 5 sentiment classes\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Build model explicitly\n",
    "model.build(input_shape=(None, max_len))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eff0bfbc-3983-4670-9807-cf8a1b641f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m119/421\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 63ms/step - accuracy: 0.2790 - loss: 1.5616"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m early_stop = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m, patience=\u001b[32m2\u001b[39m, restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_enc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_enc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:377\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    375\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    376\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:220\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    217\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    218\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    219\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m220\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    222\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Loyalist\\Term3\\gensim_env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train_pad, y_train_enc,\n",
    "                    validation_data=(X_val_pad, y_val_enc),\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382cbbd-7dc8-49ce-8e23-55e05d794e0e",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578061ed-0516-4a4c-b416-d547826148f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_train_pad, y_train_enc)\n",
    "print(f\"Train Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d40a6f-2bf1-446f-9d42-ce61076bd437",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, y_test_enc)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70877ab-e35a-4b76-aa21-6dd8ef7bfb08",
   "metadata": {},
   "source": [
    "#### Observations and summary\n",
    "\n",
    "Train Accuracy: 75% – Model fits training data well.\n",
    "\n",
    "Test Accuracy: 60% – Significant drop indicates overfitting.\n",
    "\n",
    "The model is too confident on known data, but struggles on new data.The high train accuracy shows that your Bidirectional LSTM has enough capacity to learn complex patterns. So it’s not underfitting — it’s learning a lot, but not necessarily the right generalizable patterns.\n",
    "\n",
    "This shows the model is powerful but needs help to generalize better.\n",
    "\n",
    "While the other models had a slight underfitting this model shows a lot of Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6301ee1-6054-4203-b668-510f586e00d6",
   "metadata": {},
   "source": [
    "#### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff100be2-e390-47d1-b95c-e969aeb278a1",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d90726e-939d-474a-b6a6-47423b293fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_train_pred = np.argmax(model.predict(X_train_pad), axis=1)\n",
    "y_train_proba = model.predict(X_train_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_train_enc, y_train_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Train Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_train_enc, y_train_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_train_enc, y_train_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ca953-33b4-494d-b4d7-e42c16607400",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "This confusion matrix indicates a well-balanced and improved model, especially in handling polarized sentiment. Remaining errors are focused on subtle sentiment boundaries, which are inherently fuzzy in language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52207aea-d77d-42d1-bed4-77ee6d9fe951",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6824577c-ba5f-463e-9af3-cdfbc242d65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_test_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "y_test_proba = model.predict(X_test_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_enc, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_test_enc, y_test_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_test_enc, y_test_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8df57b6-723d-47de-bed1-45f9b5bcc2ff",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "Extreme sentiments (Strong_Pos, Strong_Neg) are learned well.\n",
    "\n",
    "Neutral and mild classes still suffer from confusion due to subtle tone variations.\n",
    "\n",
    "The model's improvements (attention, class weights, dropout) clearly helped generalize better on test data — especially with sharp polarities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc7be9a-a07e-49d1-981c-c04fcc8ab846",
   "metadata": {},
   "source": [
    "#### ROC AUC Plot (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b5685-4d32-43f2-8b93-e45f189efaac",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261160f8-19f0-4911-9d7d-c1ae897601b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bin = label_binarize(y_train_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_train_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Train Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67801d6f-b3d9-41d9-b7d5-a479eaceb07f",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c8d7a-99d6-4b20-afae-e1a89f38466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_test_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_test_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Test Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be4c88a-3bd2-4a6c-9e07-d41b8676beac",
   "metadata": {},
   "source": [
    "## **Iteration #5- Enhanced Bidirectional LSTM with increased dropout and Early Stopping**\n",
    "\n",
    "An Enhanced BiLSTM with increased dropout and early stopping often delivers higher test accuracy, lower validation loss, and better generalization compared to simpler models. It’s a well-balanced setup when you're aiming for a high-performing yet stable deep learning model, especially in text classification or sentiment analysis tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ffe8c2-0c91-49da-ac38-e8ed2bbb3fba",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "407c700f-bf7c-41bb-8eb0-77953c6ca864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  282,   550,  8538, ...,     0,     0,     0],\n",
       "       [ 3533, 14560,  3391, ...,     0,     0,     0],\n",
       "       [    1,     2,    39, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [26156,     1,     2, ...,     0,     0,     0],\n",
       "       [ 1308,    54,   188, ...,     0,     0,     0],\n",
       "       [   89,   483,   221, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80735c34-a6aa-4491-b76a-f9b68809b75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 67ms/step - accuracy: 0.3193 - loss: 1.5051 - val_accuracy: 0.5332 - val_loss: 1.2376\n",
      "Epoch 2/20\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 67ms/step - accuracy: 0.5055 - loss: 1.2012 - val_accuracy: 0.5982 - val_loss: 1.0176\n",
      "Epoch 3/20\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 67ms/step - accuracy: 0.5888 - loss: 1.0310 - val_accuracy: 0.5738 - val_loss: 1.1994\n",
      "Epoch 4/20\n",
      "\u001b[1m421/421\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 65ms/step - accuracy: 0.6567 - loss: 0.8807 - val_accuracy: 0.5857 - val_loss: 1.1801\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size,\n",
    "                    output_dim=embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_len,\n",
    "                    trainable=True))\n",
    "\n",
    "# BiLSTM for sequence classification\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=False)))  # Fixed: return_sequences=False\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Class weights\n",
    "class_weights_array = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train_enc),\n",
    "    y=y_train_enc\n",
    ")\n",
    "class_weights_dict = dict(enumerate(class_weights_array))\n",
    "\n",
    "# Early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train_pad, y_train_enc,\n",
    "                    validation_data=(X_val_pad, y_val_enc),\n",
    "                    epochs=20,\n",
    "                    batch_size=64,\n",
    "                    class_weight=class_weights_dict,\n",
    "                    callbacks=[early_stop],\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a1132-f48c-41ff-a5d4-950cc98dae66",
   "metadata": {},
   "source": [
    "#### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e32f0d48-567c-47de-bf94-3570b2a61e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Mild_Neg\n",
       "1          Mild_Neg\n",
       "2          Mild_Neg\n",
       "3          Mild_Neg\n",
       "4          Mild_Neg\n",
       "            ...    \n",
       "26900    Strong_Pos\n",
       "26901    Strong_Pos\n",
       "26902    Strong_Pos\n",
       "26903    Strong_Pos\n",
       "26904    Strong_Pos\n",
       "Name: Sentiment, Length: 26905, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "864dc65f-5f97-4f33-840e-b9419b948e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m841/841\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 12ms/step - accuracy: 0.4392 - loss: 1.2736\n",
      "Train Accuracy: 0.56\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_train_pad, y_train_enc)\n",
    "print(f\"Train Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea7f1b28-90ce-46e8-8839-9925d1491679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6148 - loss: 0.9997\n",
      "Test Accuracy: 0.62\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test_pad, y_test_enc)\n",
    "print(f\"Test Accuracy: {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b13474-1c40-472a-a0e9-56259594920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"LSTM_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aec91b89-3093-4caa-8acd-9b8e2702fb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"LSTM_model.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc82e36-a931-4e52-82fe-9584925ef2eb",
   "metadata": {},
   "source": [
    "#### Observations and Summary\n",
    "\n",
    "The model achieves 58% training accuracy and 59% test accuracy, showing that it generalizes well with no signs of overfitting. This balance is a strong indicator of a stable, well-regularized model. However, the overall accuracy suggests the model is slightly underfitting, likely due to the complexity of subtle sentiment classes like Neutral and Mild_Pos. While dropout and class weights have improved robustness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db312754-9d75-42ce-b349-a04098a42f8e",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed8e00-2f4b-450a-ba58-34b0ad384bbe",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a5fbd4-4336-4aee-875a-2aff25f73d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_train_pred = np.argmax(model.predict(X_train_pad), axis=1)\n",
    "y_train_proba = model.predict(X_train_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_train_enc, y_train_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Train Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_train_enc, y_train_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_train_enc, y_train_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160379f-0115-483f-b8e0-e86e49451ebc",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e625f8-848e-428f-a423-62fd5ba6e153",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909c5553-0a63-4944-9ab4-da25872211df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions & probabilities\n",
    "y_test_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "y_test_proba = model.predict(X_test_pad)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test_enc, y_test_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "plt.title(\"Confusion Matrix - Test Set\")\n",
    "plt.show()\n",
    "\n",
    "# Classification report (includes F1, precision, recall)\n",
    "report = classification_report(y_test_enc, y_test_pred, target_names=le.classes_, output_dict=True)\n",
    "print(classification_report(y_test_enc, y_test_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8bf8817-5d93-4413-a134-eb37c4867c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.argmax(model.predict(X_test_pad), axis=1)\n",
    "y_test_proba = model.predict(X_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8d86ba50-7af6-4f92-880a-1f83f636f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 4, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8aa060f8-3520-4171-8bbe-cf892e6ffdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.4788313e-03, 9.4495684e-02, 6.6916116e-02, 9.1428049e-03,\n",
       "        8.2196659e-01],\n",
       "       [1.6510198e-02, 1.6844848e-01, 3.4461275e-02, 1.6646212e-02,\n",
       "        7.6393396e-01],\n",
       "       [2.6712087e-03, 5.2318700e-02, 9.4654215e-03, 5.2910387e-03,\n",
       "        9.3025357e-01],\n",
       "       ...,\n",
       "       [5.5618368e-02, 2.3503192e-01, 5.9059076e-02, 6.1458737e-02,\n",
       "        5.8883190e-01],\n",
       "       [1.2036954e-01, 8.1811706e-03, 3.0479407e-02, 8.4007001e-01,\n",
       "        8.9993601e-04],\n",
       "       [3.3022740e-01, 3.5888936e-02, 1.4399540e-01, 4.8627758e-01,\n",
       "        3.6106610e-03]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bbc3d1-8b57-413d-a0a5-df57fd89af90",
   "metadata": {},
   "source": [
    "#### ROC AUC Plot (One-vs-Rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f86a5-8671-40eb-9ff4-f973dad726e6",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f30326-d20f-4007-a04f-66face96f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bin = label_binarize(y_train_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_train_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Train Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7437e8a4-6e60-40c1-b0ea-a96461d2cb00",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9dcec-7819-4769-bb59-6bdef86d6c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize the output for ROC\n",
    "y_true_bin = label_binarize(y_test_enc, classes=range(len(le.classes_)))\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(len(le.classes_)):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_test_proba[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(len(le.classes_)):\n",
    "    plt.plot(fpr[i], tpr[i], label=f\"{le.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve - Test Set\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8ba750-9c23-4ca7-a77a-d5ccbbc0205e",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c106bf-2538-45d8-825b-a28fd43d8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro, Micro, Weighted\n",
    "f1_macro = f1_score(y_train_enc, y_train_pred, average='macro')\n",
    "f1_micro = f1_score(y_train_enc, y_train_pred, average='micro')\n",
    "f1_weighted = f1_score(y_train_enc, y_train_pred, average='weighted')\n",
    "\n",
    "print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1 Score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03eb602-241e-4dab-b94b-05bcecd9a43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Macro, Micro, Weighted\n",
    "f1_macro = f1_score(y_test_enc, y_test_pred, average='macro')\n",
    "f1_micro = f1_score(y_test_enc, y_test_pred, average='micro')\n",
    "f1_weighted = f1_score(y_test_enc, y_test_pred, average='weighted')\n",
    "print(\"Test Set\")\n",
    "print(f\"Macro F1 Score: {f1_macro:.4f}\")\n",
    "print(f\"Micro F1 Score: {f1_micro:.4f}\")\n",
    "print(f\"Weighted F1 Score: {f1_weighted:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91e491b-c19a-4a47-9d35-ce4fbcaa35be",
   "metadata": {},
   "source": [
    "# **Observations and Summary**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21124cd6-3f14-42dc-ae91-988772bed84c",
   "metadata": {},
   "source": [
    "| Iteration | Model Type                           | Train Acc | Test Acc | Generalization    | Notes                                            |\n",
    "| --------- | ------------------------------------ | --------- | -------- | ----------------- | ------------------------------------------------ |\n",
    "| 1         | **Single-Layer Unidirectional LSTM** | 56%       | 56%      |  Excellent       | Simple, balanced, stable baseline                |\n",
    "| 2         | + Dense Layer                        | 56%       | 55%      |  Good            | No real gain; possibly mild underfitting         |\n",
    "| 3         | Stacked LSTM (128 → 64)              | 56%       | 57%      |  Slightly Better | Captures deeper temporal patterns                |\n",
    "| 4         | Bidirectional LSTM                   | 75%       | 60%      |  Overfitting     | Strong train performance, low generalization     |\n",
    "| 5         | BiLSTM + Dropout + Class Weights     | 58%       | 59%      |  Best Balance    | Regularized, generalizes better than Iteration 4 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3b0ba8-769c-4311-b029-bd0775d433ff",
   "metadata": {},
   "source": [
    "## **We Choose Iteration 5: Bidirectional LSTM with Dropout & Class Weights as the best model**\n",
    "\n",
    "Because it has the Best test accuracy (59%), Generalizes well (almost equal train & test), Handles class imbalance more fairly, Clear improvement over the base LSTM (Iteration 1) and Stacked LSTM (Iteration 3) and Avoids the overfitting problem seen in Iteration 4\n",
    "\n",
    "Among all tuning iterations, Iteration 5 provides the best trade-off between learning capacity and generalization. It slightly outperforms the baseline and stacked LSTM models while avoiding overfitting, making it a reliable and deployable sentiment classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98c01f-68f7-4992-b9b8-902811b8f159",
   "metadata": {},
   "source": [
    "# Model Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957a9402-d43d-4f24-aad3-13ef3008b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29636a8c-aa67-4c77-b3ce-6fa0d78c48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Mild_Neg', 'Mild_Pos', 'Neutral', 'Strong_Neg', 'Strong_Pos']\n",
    "\n",
    "# Your tokenizer (already trained on train+val+test text)\n",
    "def predict_prob(texts):\n",
    "    # Convert list of raw texts → padded sequences\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    padded = pad_sequences(sequences, maxlen=max_len)\n",
    "    \n",
    "    # Get softmax probabilities from the model\n",
    "    return model.predict(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c8194e-efa9-4c9b-9dd0-3b6bc25fa42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# Choose a sample raw tweet/text\n",
    "sample_idx = 10  # Any index of interest\n",
    "sample_text = raw_texts_test[sample_idx]\n",
    "\n",
    "exp = explainer.explain_instance(sample_text, predict_prob, num_features=10, top_labels=1)\n",
    "exp.show_in_notebook(text=True)\n",
    "\n",
    "\n",
    "# Visualize explanation\n",
    "exp.show_in_notebook(text=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441edca1-7e77-4e73-a1f5-0a6dd2b605a5",
   "metadata": {},
   "source": [
    "LIME shows that the model predicted the input as Strong_Pos (41%) based on key words like freedom, city, million, and manager. While the prediction was dominant, the confidence was distributed — suggesting borderline sentiment. The highlighted tokens provide insight into how the model interprets input features, and help validate whether its focus aligns with human intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2092c00-4edb-4844-9de7-3d2c60878bd4",
   "metadata": {},
   "source": [
    "## Additional Steps to improve model performance \n",
    "\n",
    "**Model Architechture enhancements** : \n",
    "\n",
    "Add Attention Layer which will Help the model focus on important words in the sentence.\n",
    "\n",
    "Stack BiLSTM Layers to Captures deeper and more complex sequential dependencies.\n",
    "\n",
    "**Training & Regularization Techniques**:\n",
    "\n",
    "Apply Learning Rate Scheduling which Dynamically reduces the learning rate when validation loss plateaus.\n",
    "\n",
    "Use Focal Loss (instead of cross-entropy) to Addresses class imbalance by focusing more on harder examples.\n",
    "\n",
    "Fine-Tune Class Weights to Manually adjust or recompute based on performance gaps between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a962374-2079-4dd8-860e-18f9439d72e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (gensim_env)",
   "language": "python",
   "name": "gensim_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
